{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xfact_lslms.client.lslms_client import LSMSClient\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_opt30b = LSMSClient(username='', password='', model_name='opt-iml-max-30b')\n",
    "client_opt1b = LSMSClient(username='', password='', model_name='opt-iml-max-1.3b')\n",
    "client_t0 = LSMSClient(username='', password='', model_name='t0pp')\n",
    "client_t5 = LSMSClient(username='', password='', model_name='flan-t5-xxl')\n",
    "\n",
    "generate_kwargs={'max_length': 100, 'penalty_alpha': 0.6, 'top_k': 4}\n",
    "tokenizer_kwargs={'padding':True}\n",
    "\n",
    "lines = open('GenRead/indatasets/nq/nq-test.jsonl', encoding='utf8').readlines()\n",
    "lines = [json.loads(l) for l in lines]\n",
    "num_samples = 4\n",
    "\n",
    "prompt_s1 = \"Generate a background document from Wikipedia to answer the given question. \\n\\n {query} \\n\\n\"\n",
    "prompt_s2 = \"Refer to the passage below and answer the following question with just one entity. \\n\\n Passage: {background} \\n\\n Question: {query} \\n\\n The answer is\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''If 2 power 1 = 2, 2 power 2 = 4 then what is 2 power 9'''\n",
    "#text = f\"Reason with \\n\\n Question: {text} \\n\\n\"\n",
    "\n",
    "print(client_t5.call(text, generate_kwargs=generate_kwargs, tokenizer_kwargs=tokenizer_kwargs)['decoded_text'][0])\n",
    "print()\n",
    "print(client_t0.call(text, generate_kwargs=generate_kwargs, tokenizer_kwargs=tokenizer_kwargs)['decoded_text'][0])\n",
    "print()\n",
    "print(client_opt1b.call(text, generate_kwargs=generate_kwargs, tokenizer_kwargs=tokenizer_kwargs)['decoded_text'][0][len(text):])\n",
    "print()\n",
    "print(client_opt30b.call(text, generate_kwargs=generate_kwargs, tokenizer_kwargs=tokenizer_kwargs)['decoded_text'][0][len(text):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_opt30b.call(text, generate_kwargs=generate_kwargs, tokenizer_kwargs=tokenizer_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in random.sample(lines, num_samples):\n",
    "    question, answer = line['question'], line['answer']\n",
    "    print(f'Question: {question} \\t Answer: {answer}')\n",
    "    \n",
    "    query_s1 = prompt_s1.replace('{query}', question)\n",
    "    query_s2 = prompt_s2.replace('{query}', question)\n",
    "    \n",
    "    ###########################################\n",
    "    ###########################################\n",
    "\n",
    "    responce = client_opt30b.call(query_s1, \n",
    "                           generate_kwargs=generate_kwargs,\n",
    "                           tokenizer_kwargs=tokenizer_kwargs)\n",
    "\n",
    "    background = responce['decoded_text'][0][len(query_s1):]\n",
    "    print(f'Generated background using OPT_IML_MAX_30b is: {background}')\n",
    "\n",
    "    responce = client_t5.call(query_s2.replace('{background}', background), \n",
    "                           generate_kwargs=generate_kwargs,\n",
    "                           tokenizer_kwargs=tokenizer_kwargs)\n",
    "    print(f\"Repsonse: {responce['decoded_text']}\")\n",
    "\n",
    "    ###########################################\n",
    "    responce = client_opt1b.call(query_s1, \n",
    "                           generate_kwargs=generate_kwargs,\n",
    "                           tokenizer_kwargs=tokenizer_kwargs)\n",
    "\n",
    "    background = responce['decoded_text'][0][len(query_s1):]\n",
    "    print(f'Generated background using OPT_IML_MAX_1b is: {background}')\n",
    "\n",
    "    responce = client_t5.call(query_s2.replace('{background}', background), \n",
    "                           generate_kwargs=generate_kwargs,\n",
    "                           tokenizer_kwargs=tokenizer_kwargs)\n",
    "    print(f\"Repsonse: {responce['decoded_text']}\")\n",
    "\n",
    "    ###########################################\n",
    "    responce = client_t0.call(query_s1, \n",
    "                           generate_kwargs=generate_kwargs,\n",
    "                           tokenizer_kwargs=tokenizer_kwargs)\n",
    "\n",
    "    background = responce['decoded_text'][0]\n",
    "    print(f'Generated background using t0 is: {background}')\n",
    "\n",
    "    responce = client_t0.call(query_s2.replace('{background}', background), \n",
    "                           generate_kwargs=generate_kwargs,\n",
    "                           tokenizer_kwargs=tokenizer_kwargs)\n",
    "    print(f\"Repsonse: {responce['decoded_text']}\")\n",
    "\n",
    "    ###########################################\n",
    "    responce = client_t5.call(query_s1, \n",
    "                           generate_kwargs=generate_kwargs,\n",
    "                           tokenizer_kwargs=tokenizer_kwargs)\n",
    "\n",
    "    background = responce['decoded_text'][0]\n",
    "    print(f'Generated background using t5 is: {background}')\n",
    "\n",
    "    responce = client_t5.call(query_s2.replace('{background}', background), \n",
    "                           generate_kwargs=generate_kwargs,\n",
    "                           tokenizer_kwargs=tokenizer_kwargs)\n",
    "    print(f\"Repsonse: {responce['decoded_text']}\")\n",
    "\n",
    "    ###########################################\n",
    "    \n",
    "    \n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Determanistic\n",
    "\n",
    "# bf16:\n",
    "# Propmt: What is the best movie by IMDb? Explain it's plot as well\n",
    "# Responce: 'The movie is a great example of the movie. It is a great movie.'\n",
    "# Prompt: translate English to German: The house is wonderful\n",
    "# Responce: Das Haus ist schön.\n",
    "\n",
    "# Float32\n",
    "# Propmt: What is the best movie by IMDb? Explain it's plot as well\n",
    "# Responce: The best movie by IMDb\n",
    "# Prompt: translate English to German: The house is wonderful\n",
    "# Responce: Das Haus ist schön.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example from the datasets ag_news\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "example = dataset[1]\n",
    "\n",
    "# Load prompts for this dataset\n",
    "from promptsource.templates import DatasetTemplates\n",
    "ag_news_prompts = DatasetTemplates('imdb')\n",
    "\n",
    "# Print all the prompts available for this dataset. The keys of the dict are the uuids the uniquely identify each of the prompt, and the values are instances of `Template` which wraps prompts\n",
    "print(ag_news_prompts.templates)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_news_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a prompt by its name\n",
    "prompt = ag_news_prompts[\"classify_question_first\"]\n",
    "\n",
    "# Apply the prompt to the example\n",
    "result = prompt.apply(example)\n",
    "print(\"INPUT: \", result[0])\n",
    "print(\"TARGET: \", result[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
